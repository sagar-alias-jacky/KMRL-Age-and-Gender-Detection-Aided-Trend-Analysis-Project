{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacky/Downloads/temporary/age-gender-main/age-gender/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import io\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import jsonpickle\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import io\n",
    "import logging\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.model import ResMLP\n",
    "from utils import enable_dropout, forward_mc, read_json\n",
    "\n",
    "from flask import Flask, request\n",
    "import logging\n",
    "from insightface.app.face_analysis import FaceAnalysis as FaceDetectionRecognition\n",
    "import numpy as np\n",
    "import argparse\n",
    "import io\n",
    "from PIL import Image\n",
    "from utils import resize_square_image, get_original_bbox, get_original_lm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Age and Gender Estimation Model Flask Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      "Dropout(p=0.05, inplace=False)\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:10003\n",
      " * Running on http://192.168.1.6:10003\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# a light-weight flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "models = {\"age\": None, \"gender\": None}\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\"\n",
    "\n",
    "for model_ in [\"age\", \"gender\"]:\n",
    "    model = ResMLP(**read_json(f\"./models/{model_}.json\")[\"arch\"][\"args\"])\n",
    "    checkpoint = f\"models/{model_}.pth\"\n",
    "    checkpoint = torch.load(checkpoint, map_location=torch.device(device))\n",
    "    state_dict = checkpoint[\"state_dict\"]\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    enable_dropout(model)\n",
    "\n",
    "    models[model_] = model\n",
    "\n",
    "# One endpoint is enough.\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"POST\"])\n",
    "def predict_age_gender():\n",
    "    \"\"\"Receive everything in json!!!\"\"\"\n",
    "    app.logger.debug(f\"Receiving data ...\")\n",
    "    data = request.json\n",
    "    data = jsonpickle.decode(data)\n",
    "\n",
    "    app.logger.debug(f\"loading embeddings ...\")\n",
    "    embeddings = data[\"embeddings\"]\n",
    "    embeddings = io.BytesIO(embeddings)\n",
    "\n",
    "    # This assumes that the client has serialized the embeddings with pickle.\n",
    "    # before sending it to the server.\n",
    "    embeddings = np.load(embeddings, allow_pickle=True)\n",
    "\n",
    "    # -1 accounts for the batch size.\n",
    "    embeddings = embeddings.reshape(-1, 512).astype(np.float32)\n",
    "\n",
    "    app.logger.debug(f\"extracting gender and age from {embeddings.shape[0]} faces ...\")\n",
    "\n",
    "    genders = []\n",
    "    ages = []\n",
    "\n",
    "    for embedding in tqdm(embeddings):\n",
    "        embedding = embedding.reshape(1, 512)\n",
    "        gender_mean, gender_entropy = forward_mc(models[\"gender\"], embedding)\n",
    "        age_mean, age_entropy = forward_mc(models[\"age\"], embedding)\n",
    "        gender = {\"m\": 1 - gender_mean, \"f\": gender_mean, \"entropy\": gender_entropy}\n",
    "        age = {\"mean\": age_mean, \"entropy\": age_entropy}\n",
    "\n",
    "        genders.append(gender)\n",
    "        ages.append(age)\n",
    "\n",
    "    app.logger.debug(f\"gender and age extracted!\")\n",
    "\n",
    "    response = {\"ages\": ages, \"genders\": genders}\n",
    "\n",
    "    response_pickled = jsonpickle.encode(response)\n",
    "    app.logger.info(\"json-pickle is done.\")\n",
    "\n",
    "    return response_pickled\n",
    "\n",
    "\n",
    "app.run(host=\"0.0.0.0\", port=10003)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('age-gender': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c952b7deaf140ad60b711fd9f1151e1d2fae17e0c8f3f190ffdc33d4d244c59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
