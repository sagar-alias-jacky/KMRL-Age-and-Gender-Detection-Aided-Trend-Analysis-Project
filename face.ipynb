{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jacky/Downloads/temporary/age-gender-main/age-gender/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import io\n",
    "import logging\n",
    "import pickle\n",
    "\n",
    "import jsonpickle\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import io\n",
    "import logging\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "from model.model import ResMLP\n",
    "from utils import enable_dropout, forward_mc, read_json\n",
    "\n",
    "from flask import Flask, request\n",
    "import logging\n",
    "from insightface.app.face_analysis import FaceAnalysis as FaceDetectionRecognition\n",
    "import numpy as np\n",
    "import argparse\n",
    "import io\n",
    "from PIL import Image\n",
    "from utils import resize_square_image, get_original_bbox, get_original_lm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Face Detection Model Flask Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/jacky/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/jacky/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/jacky/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/jacky/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "Applied providers: ['CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}}\n",
      "find model: /home/jacky/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:10002\n",
      " * Running on http://192.168.1.6:10002\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "[2022-12-02 19:29:44,593] ERROR in app: Exception on / [POST]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jacky/Downloads/temporary/age-gender-main/age-gender/lib/python3.10/site-packages/flask/app.py\", line 2525, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/home/jacky/Downloads/temporary/age-gender-main/age-gender/lib/python3.10/site-packages/flask/app.py\", line 1822, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/home/jacky/Downloads/temporary/age-gender-main/age-gender/lib/python3.10/site-packages/flask/app.py\", line 1820, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/home/jacky/Downloads/temporary/age-gender-main/age-gender/lib/python3.10/site-packages/flask/app.py\", line 1796, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**view_args)\n",
      "  File \"/tmp/ipykernel_70202/2448314910.py\", line 40, in face_detection_recognition\n",
      "    list_of_features = fdr.get(image)\n",
      "  File \"/home/jacky/Downloads/temporary/age-gender-main/age-gender/lib/python3.10/site-packages/insightface/app/face_analysis.py\", line 59, in get\n",
      "    bboxes, kpss = self.det_model.detect(img,\n",
      "  File \"/home/jacky/Downloads/temporary/age-gender-main/age-gender/lib/python3.10/site-packages/insightface/model_zoo/retinaface.py\", line 208, in detect\n",
      "    assert input_size is not None or self.input_size is not None\n",
      "AssertionError\n",
      "127.0.0.1 - - [02/Dec/2022 19:29:44] \"\u001b[35m\u001b[1mPOST / HTTP/1.1\u001b[0m\" 500 -\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "# gender age estimaion are bad. We don't use them here.\n",
    "fdr = FaceDetectionRecognition(det_name='retinaface_r50_v1',\n",
    "                               rec_name='arcface_r100_v1',\n",
    "                               ga_name=None)\n",
    "\n",
    "\n",
    "@app.route(\"/\", methods=[\"POST\"])\n",
    "def face_detection_recognition():\n",
    "    \"\"\"Receive everything in json!!!\n",
    "    \"\"\"\n",
    "    app.logger.debug(f\"Receiving data ...\")\n",
    "    data = request.json\n",
    "    data = jsonpickle.decode(data)\n",
    "\n",
    "    app.logger.debug(f\"decompressing image ...\")\n",
    "    image = data['image']\n",
    "    image = io.BytesIO(image)\n",
    "\n",
    "    app.logger.debug(f\"Reading a PIL image ...\")\n",
    "    image = Image.open(image)\n",
    "    image_size_original = image.size\n",
    "\n",
    "    app.logger.debug(f\"Resizing a PIL image to 640 by 640 ...\")\n",
    "    image = resize_square_image(image, 640, background_color=(0, 0, 0))\n",
    "    image_size_new = image.size\n",
    "\n",
    "    app.logger.debug(f\"Conveting a PIL image to a numpy array ...\")\n",
    "    image = np.array(image)\n",
    "\n",
    "    if len(image.shape) != 3:\n",
    "        app.logger.error(f\"image shape: {image.shape} is not RGB!\")\n",
    "        del data, image\n",
    "        response = {'face_detection_recognition': None}\n",
    "        response_pickled = jsonpickle.encode(response)\n",
    "        return response_pickled\n",
    "\n",
    "    app.logger.info(f\"extraing features ...\")\n",
    "    list_of_features = fdr.get(image)\n",
    "    app.logger.info(f\"features extracted!\")\n",
    "\n",
    "    app.logger.info(f\"In total of {len(list_of_features)} faces detected!\")\n",
    "\n",
    "    results_frame = []\n",
    "    for features in list_of_features:\n",
    "        bbox = get_original_bbox(features.bbox, image_size_original, image_size_new)\n",
    "        landmark = get_original_lm(features.landmark, image_size_original, image_size_new)\n",
    "        feature_dict = {'bbox': bbox,\n",
    "                        'det_score': features.det_score,\n",
    "                        'landmark': landmark,\n",
    "                        'normed_embedding': features.normed_embedding\n",
    "                        }\n",
    "        results_frame.append(feature_dict)\n",
    "\n",
    "    response = {'face_detection_recognition': results_frame}\n",
    "    app.logger.info(\"json-pickle is done.\")\n",
    "\n",
    "    response_pickled = jsonpickle.encode(response)\n",
    "\n",
    "    return response_pickled\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # parser = argparse.ArgumentParser()\n",
    "    # parser.add_argument('--gpu-id', type=int, default=-1, help='-1 means CPU')\n",
    "    # args = parser.parse_args()\n",
    "    # args = vars(args)\n",
    "    # fdr.prepare(ctx_id=args['gpu_id'])\n",
    "    app.run(host='0.0.0.0', port=10002)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('age-gender': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0c952b7deaf140ad60b711fd9f1151e1d2fae17e0c8f3f190ffdc33d4d244c59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
